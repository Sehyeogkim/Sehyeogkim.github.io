<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Ch1. Optimization for Deep Learning | Sehyeog Kim</title>
  <link rel="stylesheet" href="../../../assets/css/style.css">
</head>
<body>
  <!-- Mobile header -->
  <header class="mobile-header">
    <span class="site-title">Sehyeog Kim</span>
    <button class="menu-toggle" aria-label="Menu">&#9776;</button>
  </header>
  <div class="sidebar-overlay"></div>

  <div class="site-wrapper">
    <!-- Sidebar -->
    <aside class="sidebar">
      <div class="sidebar-bg">
        <img src="../../../assets/images/bg.jpg" alt="Background"
             onerror="this.style.display='none'">
      </div>
      <div class="sidebar-profile">
        <img class="profile-photo"
             src="../../../assets/images/profile.jpg"
             alt="Sehyeog Kim"
             onerror="this.style.background='#21262d'">
        <h1 class="profile-name">Sehyeog Kim</h1>
        <p class="profile-bio">AI &amp; Computational Engineering<br>Knowledge Base</p>
        <div class="profile-links">
          <a href="https://github.com/Sehyeogkim" target="_blank" rel="noopener">
            <svg viewBox="0 0 16 16" width="16" height="16" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg> GitHub
          </a>
        </div>
      </div>
      <nav class="sidebar-nav">
        <a href="/" class="nav-item nav-home">Home</a>
        <span class="nav-label">Categories</span>
        <a href="/blog/advanced-engineering-mathematics/" class="nav-item">Advanced_Engineering_Mathematics<span class="nav-post-count">14</span></a>
        <a href="/blog/agentic-ai/" class="nav-item">Agentic_AI<span class="nav-post-count">8</span></a>
        <a href="/blog/blood-flow-and-metabolism/" class="nav-item">Blood-Flow-and-Metabolism<span class="nav-post-count">12</span></a>
        <a href="/blog/cardiovascular-diseases/" class="nav-item">CardioVascular_Diseases<span class="nav-post-count">8</span></a>
        <a href="/blog/computational-linear-algebra/" class="nav-item">Computational-Linear-Algebra<span class="nav-post-count">15</span></a>
        <a href="/blog/continuum-mechanics/" class="nav-item">Continuum-Mechanics<span class="nav-post-count">9</span></a>
        <a href="/blog/deep-learning/" class="nav-item active">Deep-learning<span class="nav-post-count">14</span></a>
        <a href="/blog/finite-element-method/" class="nav-item">Finite-Element-Method<span class="nav-post-count">1</span></a>
        <a href="/blog/fluid-mechanics/" class="nav-item">Fluid_Mechanics<span class="nav-post-count">18</span></a>
        <a href="/blog/gas-dynamics/" class="nav-item">Gas_Dynamics<span class="nav-post-count">24</span></a>
        <a href="/blog/heat-transfer/" class="nav-item">Heat-transfer<span class="nav-post-count">8</span></a>
        <a href="/blog/machine-learning/" class="nav-item">Machine_Learning<span class="nav-post-count">11</span></a>
        <a href="/blog/numerical-heat-transfer-and-fluid-flow/" class="nav-item">Numerical-Heat-transfer-and-Fluid-flow<span class="nav-post-count">14</span></a>
        <a href="/blog/sensitivity-analysis/" class="nav-item">Sensitivity_Analysis<span class="nav-post-count">3</span></a>
        <a href="/blog/solid-mechanics/" class="nav-item">Solid_Mechanics<span class="nav-post-count">25</span></a>
        <a href="/blog/thermodynamics/" class="nav-item">Thermodynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/viscous-flow/" class="nav-item">Viscous_Flow<span class="nav-post-count">28</span></a>
      </nav>
    </aside>

    <!-- Main content -->
    <main class="main-content">
      <div class="breadcrumb">  <a href="/">Home</a><span class="sep">/</span>  <a href="/blog/deep-learning/">Deep-learning</a><span class="sep">/</span>  <span>Ch1. Optimization for Deep Learning</span></div>
<a href="/blog/deep-learning/" class="back-link">&larr; Back to Deep-learning</a>
<div class="page-header"><h1>Ch1. Optimization for Deep Learning</h1></div>
<div class="post-meta"><span class="meta-item"><span class="meta-label">Date:</span> 2024-09-24</span><span class="meta-item"><span class="meta-label">Category:</span> Deep-learning</span><span class="meta-item"><span class="meta-label">Source:</span> <a href="https://jeffdissel.tistory.com/m/95" target="_blank" rel="noopener">link</a></span></div>
<article class="post-content"><p>Ch1. Optimization for Deep Learning<br />
아마 거의 모든<br />
엔지니어링 뿐만아니라,<br />
다양한 문제들 모두 최적화<br />
Optimization<br />
문제이다.<br />
예를들어,<br />
내가 아침 몇시에 운동을 해야 가장 기분이 좋고, 에너제틱한<br />
하루가 될 수 있을까?<br />
라는 질문도, 최적화 문제인데<br />
해결하는 방법은<br />
y = f(x)<br />
x:input, y:output<br />
에서 함수 f 를 정의하는 것이다.<br />
예를들어, 나만의 작년<br />
365일의 데이터를 토대로,<br />
겨울이 될 수록 해가 늦게 뜨니까, 더 늦게 운동을 해야 된다면,<br />
y = x/12 + 6<br />
x: (단위: 월)<br />
y: (단위: 시)<br />
이런식으로, 식을 세울 수 있을 것이다.<br />
그런데, 전날 잔 시간, 전날 마신 술의 양, 전날 받은 스트레스양<br />
등등 다양한 요인들이<br />
종합적으로 고려되어야 할 것이다.<br />
이럴 경우, f(x)를 정의하면 좋지만,<br />
정확히 define 하기 어려운 경우가 많다.<br />
이때, 강력한 해결책이 바로,<br />
Deep Learning<br />
정확히 말하면, 딥러닝은<br />
<img alt="Ch1. Optimization for Deep Learning" src="./images/img-001.png" /><br />
이렇게, 최소의 해(min)을<br />
찾는 것을<br />
가장 잘한다.<br />
위의 예시를 보면,<br />
기분이 최고의 시간 = output으로<br />
우리가 도출 하고 싶었었다.<br />
그렇다면,<br />
(기분의 정도) * (-1) = y<br />
로 재 정의하면,<br />
최저의 y를 구하는 문제로<br />
변하게 된다.<br />
결국, 우리는 y = f(x) - min 일때의 x (아침 시간)<br />
을 찾는 것이다.<br />
이렇게, 일부러 Min을 구하는 문제로 변형시켜 주면,<br />
딥러닝을 사용하기 좋은 것이다.<br />
이제, y=f(x) -&gt; min 값일때의 x<em>을 찾아내는 방법을 알아보자.<br />
Gradient Decent Method<br />
<img alt="Ch1. Optimization for Deep Learning" src="./images/img-002.png" /><br />
아주 간단하다,<br />
x백터의, 그레이디언트 백터를 정의하고,<br />
<img alt="Ch1. Optimization for Deep Learning" src="./images/img-003.png" /><br />
연속, 미분가능한 f에서<br />
최적의 point는<br />
기울기 = 0 인 지점일 것이다.<br />
(unconstrained op 는 x에 제약 조건이 없는 것이다)<br />
(e.g) x&gt;=0 조건이 있으면, constrained Op<br />
<img alt="Ch1. Optimization for Deep Learning" src="./images/img-004.png" /><br />
그렇다면, x0에서 시작하고,<br />
기울기에 alpha(step size)를 곱한 값만큼<br />
x를 움직이는 것이다.<br />
이 과정을 f'(x) = 0인 순간까지 진행하여<br />
최적의 x</em>를 찾아내는 것이다<br />
<img alt="Ch1. Optimization for Deep Learning" src="./images/img-005.png" /><br />
<img alt="Ch1. Optimization for Deep Learning" src="./images/img-006.png" /><br />
보통 이렇게, x가 다차원인 경우가 많다.<br />
x=(x1,x2,x3,...xn)<br />
실제 x,y - input, z - output<br />
인경우, z최소가 되는 최적의 x,y,를<br />
Gradient Decent방법을 사용하면<br />
밑의 그림의 과정을 거친다.<br />
<img alt="Ch1. Optimization for Deep Learning" src="./images/img-007.png" /><br />
여기서, 아까 Step size를 alpha를 살펴보면<br />
alpha가 클수록, x 값이 급격하게 변화함을 알 수 있다.<br />
따라서, step size 가 너무 작으면, 연산시간이 오래걸리고,<br />
너무 크게 되면 가운데 사진처럼 overshoot 현상이 일어난다.<br />
<img alt="Ch1. Optimization for Deep Learning" src="./images/img-008.png" /><br />
여기서, 하지만 한가지 짚고 넘어가야할 부분,<br />
Gradient decent방법이<br />
Convex인 경우는<br />
local min = global min이지만,<br />
<img alt="Ch1. Optimization for Deep Learning" src="./images/img-009.png" /><br />
Non-convex같은 경우는<br />
local min != global min일 수 있다.<br />
즉, 시작지점이 어디냐에 따라서, min값이 달라지게 된다는 것이다.<br />
결국, 다양한 시작점에서 진행해본후,<br />
global min값을 찾아야 한다.</p></article>
      <footer class="site-footer">
        <p>&copy; 2026 Sehyeog Kim. Built with gitfolio-inspired theme.</p>
      </footer>
    </main>
  </div>

  <script src="../../../assets/js/main.js"></script>
</body>
</html>