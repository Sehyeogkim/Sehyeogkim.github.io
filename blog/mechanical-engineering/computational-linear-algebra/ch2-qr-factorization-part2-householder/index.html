<!DOCTYPE html>
<html lang="ko" data-theme="light">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>2. QR factorization - part2 (Householder) | Sehyeog Kim</title>
  <link rel="stylesheet" href="../../../../assets/css/style.css">
  <script>!function(){var t=localStorage.getItem("theme")||"light";document.documentElement.setAttribute("data-theme",t)}();</script>
</head>
<body>
  <button class="theme-toggle" aria-label="Toggle theme"><svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg><svg class="icon-moon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/></svg></button>

  <header class="mobile-header">
    <span class="site-title">Sehyeog Kim</span>
    <button class="menu-toggle" aria-label="Menu">&#9776;</button>
  </header>
  <div class="sidebar-overlay"></div>

  <div class="site-wrapper">
    <aside class="sidebar">
      <div class="sidebar-bg">
        <img src="../../../../assets/images/bg.jpg" alt="Background" onerror="this.style.display='none'">
      </div>
      <div class="sidebar-profile">
        <img class="profile-photo" src="../../../../assets/images/profile.jpg" alt="Sehyeog Kim"
             onerror="this.style.background='#eaeef2'">
        <h1 class="profile-name">Sehyeog Kim</h1>
        <p class="profile-bio">AI &amp; Computational Engineering<br>Personal Blog</p>
        <div class="profile-links">
          <a href="https://github.com/Sehyeogkim" target="_blank" rel="noopener">
            <svg viewBox="0 0 16 16" width="15" height="15" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg> GitHub
          </a>
        </div>
      </div>
      <nav class="sidebar-nav">
        <a href="/" class="nav-item nav-home">Home</a>
        <span class="nav-group-label">AI</span>
        <a href="/blog/ai/agentic-ai-theory/" class="nav-item">Agentic_AI_Theory<span class="nav-post-count">8</span></a>
        <a href="/blog/ai/deep-learning/" class="nav-item">Deep-learning<span class="nav-post-count">14</span></a>
        <a href="/blog/ai/machine-learning/" class="nav-item">Machine_Learning<span class="nav-post-count">11</span></a>
        <a href="/blog/ai/sensitivity-analysis/" class="nav-item">Sensitivity_Analysis<span class="nav-post-count">3</span></a>
        <span class="nav-group-label">BioMechanics</span>
        <a href="/blog/biomechanics/blood-flow-and-metabolism/" class="nav-item">Blood-Flow-and-Metabolism<span class="nav-post-count">12</span></a>
        <a href="/blog/biomechanics/cardiovascular-diseases/" class="nav-item">CardioVascular_Diseases<span class="nav-post-count">8</span></a>
        <span class="nav-group-label">Mechanical_Engineering</span>
        <a href="/blog/mechanical-engineering/computational-linear-algebra/" class="nav-item active">Computational-Linear-Algebra<span class="nav-post-count">15</span></a>
        <a href="/blog/mechanical-engineering/computational-fluid-dynamics/" class="nav-item">Computational_Fluid_Dynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/continuum-mechanics/" class="nav-item">Continuum-Mechanics<span class="nav-post-count">9</span></a>
        <a href="/blog/mechanical-engineering/engineering-mathematics/" class="nav-item">Engineering_Mathematics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/finite-element-method/" class="nav-item">Finite-Element-Method<span class="nav-post-count">1</span></a>
        <a href="/blog/mechanical-engineering/fluid-mechanics/" class="nav-item">Fluid_Mechanics<span class="nav-post-count">18</span></a>
        <a href="/blog/mechanical-engineering/gas-dynamics/" class="nav-item">Gas_Dynamics<span class="nav-post-count">24</span></a>
        <a href="/blog/mechanical-engineering/heat-transfer/" class="nav-item">Heat-transfer<span class="nav-post-count">8</span></a>
        <a href="/blog/mechanical-engineering/solid-mechanics/" class="nav-item">Solid_Mechanics<span class="nav-post-count">25</span></a>
        <a href="/blog/mechanical-engineering/thermodynamics/" class="nav-item">Thermodynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/viscous-flow/" class="nav-item">Viscous_Flow<span class="nav-post-count">28</span></a>
      </nav>
    </aside>

    <main class="main-content">
      <div class="breadcrumb"><a href="/">Home</a><span class="sep">/</span><a href="/blog/mechanical-engineering/">Mechanical_Engineering</a><span class="sep">/</span><a href="/blog/mechanical-engineering/computational-linear-algebra/">Computational-Linear-Algebra</a><span class="sep">/</span><span>2. QR factorization - part2 (Householder)</span></div>
<a href="/blog/mechanical-engineering/computational-linear-algebra/" class="back-link">&larr; Back to Computational-Linear-Algebra</a>
<div class="page-header"><h1>2. QR factorization - part2 (Householder)</h1></div>
<div class="post-meta"><span class="meta-item"><span class="meta-label">Date:</span> 2025-09-04</span><span class="meta-item"><span class="meta-label">Category:</span> Computational-Linear-Algebra</span><span class="meta-item"><span class="meta-label">Source:</span> <a href="https://jeffdissel.tistory.com/m/221" target="_blank" rel="noopener">link</a></span></div>
<article class="post-content"><ol>
<li>QR factorization - part2 (Householder)<br />
지난시간에 QR 분해의 기본적인 원리에 대해서 살펴보았다.<br />
(정확히 본질을 이해하면, QR분해가 아무것도 아니라는 것을 알게 된다)<br />
그러니까, 어떤 A라는 matrix의 column vector들을,<br />
range(A) Basis vector{q1,q2....qn}<br />
들로 바꾸어 표현하는 것이 QR 분해이다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-001.png" /><br />
실제로 컴퓨를 활용해서, QR분해 를 하는 과정도 지난포스터(Part1)에서 살펴보았고,<br />
Gram schemdit Algorithm을 사용하였다.<br />
기본적인 원리는<br />
a1 -&gt; q1을 먼저 설정하고,<br />
a2에서 q1의 성분을 제거하고, q2를 정의<br />
a3에서는 q1,q2성분을 제거 q3를 정의<br />
하는식으로 구성하여, 전체적으로 모든 기저벡터들이 서로 orthogonal 하도록 제작.<br />
위 순차적인 과정을 하나하나 Matrix Equation으로 표현한다면,<br />
첫번째 과정은 다음과 같이 a1을 q1으로 구성하고,<br />
a2 ... an에서 q1성분을 전부 제거하는 matrix eqaution으로 표현가능하다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-002.png" /><br />
즉 위는 q1을 전부 제거해주었다면,<br />
이제 q2 ... qn을 연속적으로 전부 제거해주면<br />
우리가 원하는 Q가 나오게 된다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-003.png" /><br />
이제 오늘 포스터의 메인인<br />
Gram schemdit 다음으로 더 효율적인<br />
Computational Algorithm인 HouseHolder를<br />
살펴보자.</li>
</ol>
<h1>Householder</h1>
<p>그 전에,<br />
우리가 지난 시간에 스쳐지나가면서 배웠던,<br />
Projector (P) Matrix와 Reflector에 대해서 복습을 하고 넘어가자.</p>
<h1>Projector (P)</h1>
<p>계속해서 말하지만, tensor는 mapping이다.<br />
v1 = tensor * v2<br />
는 v2를 v1으로 mapping 전환하는 것.<br />
먼저, 고등학교때 배웠던 Projection의 개념<br />
Proj q (v) 는 v에서 q벡터 방향 성분을 추출하는 것.<br />
따라서, 내적한 스칼라값 * q = Proj q (v)<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-004.png" /><br />
스칼라 값이므로, 우리는 q를 옮겨서 tensor로 만들어 주자.<br />
(전환이 이해가 안간다면, 간단한 예시로 확인해보자)<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-005.png" /><br />
이제 우리가 계속해서 보던 mapping formulation으로 전환되었다.<br />
(vecotr = tensor * vector)<br />
우리는 q q* 를 Projector Matrix라고 부르고, 기존 벡터를<br />
q벡터 방향으로 Mapping해주는 역할을 한다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-006.png" /><br />
여기서 어떤 임의의 x벡터를 우리는 P를 이용하여 다음과 같이 q방향성분, q와 수직인 성분으로<br />
쪼갤 수 있다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-007.png" /></p>
<h1>Reflector(Q)</h1>
<p><img alt="2. QR factorization - part2 (Householder)" src="./images/img-008.png" /><br />
여기서 reflector라는 개념이 등장한다.<br />
바로 x벡터를 P와 수직인 space를 기준으로 reflection해주는 것.<br />
추상적인 개념이지만, python code로 plot해보면 쉽게 이해가 간다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-009.png" /><br />
P와 수직인 성분 (null(P) space) 를 기준으로 Mirror , reflect the x vector.<br />
왜 이런 거울을 만든 것일까...<br />
는 Householder algorithm을 자세하게 살펴보면 알 수 있다.</p>
<h1>House holder Algorithm</h1>
<p>과정은 다음과 같다. 먼저 Householder reflector를 정의한다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-010.png" /><br />
(방금전에 다루었던, reflector에서 qq<em> = vv</em> / ||v|| 으로 바꿔서 표현만 한것)<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-011.png" /><br />
여기서 refelctor에서 v를 우리는 적절히 설정하여,<br />
여기서 A에다가 곱해주면, 첫번째 column vector가 r11 e1.<br />
즉 e2,e3.... en 은 전부 존재하지 않도록 만들어준다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-012.png" /><br />
이제 또다른 새로운 reflector를 만든다.<br />
(또 적절히 v를 설정해주는게 핵심)<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-010.png" /><br />
적절히 만들어서, 위의 H1A에 곱해줬을때,<br />
두번째 column vector의 3,... n성분들이 전부 0 이 되도록 만들어준다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-013.png" /><br />
위 방식을 n번 반복하게 되면 우리는<br />
다음과 같이 H1 = Q1 , .. Hn = Qn으로 바꾸어서 표기하면,<br />
우리가 원하는 QR factorization을 달성.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-014.png" /><br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-015.png" /><br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-014.png" /><br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-015.png" /><br />
자 그렇다면, 당연히 마음속에서 드는 질문은<br />
적절한 v설정이란 어떻게 하는 걸까??? 라는 것이다.<br />
그 부분에서 지금부터 다루어보자.<br />
첫번째 H1을 제작할때 우리는 e1성분만 남기고 싶은게 목표였다.<br />
(P = H1, 여기서 householder reflector 입니다!)<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-016.png" /><br />
즉 v는 x, e1의 선형결합으로 이루어졌다는 사실.<br />
이를 Px식에 대입해주면,<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-017.png" /><br />
(이제, 우리의 관심사는 alpha값이 얼마일까? 라는 것)<br />
유도해보자.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-018.png" /><br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-019.png" /><br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-018.png" /><br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-019.png" /><br />
(v = x + alpha e1을 위 Householder Matrix에 대입을 해주자)<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-020.png" /><br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-021.png" /><br />
우리는 Householder Matrix를 곱하고 e1성분만 남게 만들고 싶다.<br />
따라서, x 성분의 계수 = 0 이 되도록하는 alpha를 구하면 됨.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-022.png" /><br />
(위 식 = 0, 전개)<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-023.png" /><br />
최종적으로 alpha는 x의 norm임을 알 수가 있다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-024.png" /><br />
(보통 부호는 x의 부호를 따라가는게 수치적안정성을 유도한다고함)<br />
바로 예시로 다시한번 확인해보자. ||x|| = 6이기 떄문에, v를 구할 수 있고,<br />
이를 가지고 Householder Matrix를 구하면 다음과 같다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-025.png" /><br />
(자 그렇다면 이런 질문이 당연히 떠오를 것이다.<br />
방금 위의 과정은 e1성분만 남기는 과정이고,<br />
H2,H3 .. Hn을 연이어서 제작하려면, e2,.. en성분을 남겨야 하는데??)<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-026.png" /><br />
우리가 분해할 행렬 A (m x n)<br />
첫번째 H1을 구하기 위해서, 사용한 x는 다음과 첫번째 열 벡터였다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-027.png" /><br />
두번째에서는 두번째 열벡터중에서도, 두번재 row부터 column vector x로 설정한다.<br />
(여기서 핵심이 바로 이것 a22부터 첫번째 요소로 설정하면,<br />
현재 설정한 column vector의 e1 -&gt; Global e2)<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-028.png" /><br />
따라서 householder 연산을 할때는 local basis를 기준으로,<br />
연산을 진행하고, 마지막에 global basis기준으로 전환을 해준다.<br />
(global 전환은 마지막 stage에서 설명)<br />
위 설정규칙을 수학적 기호로 표현하면 as follows:<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-029.png" /><br />
전부 같은 원리로 v = x + alpha e1이며, alpha = ||x||2<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-030.png" /><br />
(e1을 그대로 사용해도 괜찮다는 것이 핵심)<br />
kth HouseHolder Matrix는 다음과 같이 표기가 된다는 것.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-031.png" /><br />
즉 k에 따라서 H의 dimension이 다르게 된다!!!!<br />
마지막에 이제 우리는 QR factorization을 위해서 원래 global Basis로 전환해주면 다음과 같이,<br />
I를 이용하여 Qk를 형성할 수 있다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-032.png" /><br />
예를들어서 전체 4*4 행렬에서 Q3은 다음과 같이 전환.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-033.png" /><br />
Pseudo code로 작성한 Householder 알고리즘은 다음과 같고,<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-034.png" /><br />
전체 연산 count는<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-035.png" /><br />
loop를 n번 반복하므로, 전체 연산은 m,n에 대한 함수로 다음과 같이 나타낼 수 있다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-036.png" /><br />
여기서 생각을 해보면, Householder Algorithm으로 우리는<br />
A -&gt; H1... HnA -&gt; R<br />
최종적으로 R을 도출하였다.<br />
따라서, Q는 R을 통해서 계산을 해주어야함.<br />
(두가지 알고리즘이 존재)<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-037.png" /><br />
여기서 Householder Algorithm의 핵심은 오차 증폭이 일어나지 않는다는 점이다.<br />
지난시간에 Gram - Schemdit Algorithm에서<br />
floating 수치적 오차로 인해서, 정확히 Q가 완벽한 Orthogonal vector로 구성되지는 않는다는 점을 확인했다.<br />
같은 원리로, Householder algorithm에서도 곱셉연산시 에러가 발생하며,<br />
밑의 예시는 2번 곱할때 2개의 에러가 발생하는 상황.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-038.png" /><br />
이때 우리가 E2 = Q1 * E2'으로 분해하면, Q2Q1으로 묶어서 하나의 에러 E로 치환가능하다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-039.png" /><br />
여기서 핵심은 하나의 에러로 치환한 E의 norm을 보면,<br />
각 에러의 합보다 항상 작거나 같다.<br />
<img alt="2. QR factorization - part2 (Householder)" src="./images/img-040.png" /><br />
따라서, Gram schemdit algorithm에서 처럼,<br />
곱셉으로 인하여 에러가 증폭되는 일은 발생하지 않는다.</p></article>
      <footer class="site-footer">
        <p>&copy; 2026 Sehyeog Kim</p>
      </footer>
    </main>
  </div>
  <script src="../../../../assets/js/main.js"></script>
</body>
</html>