<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>3. Least Square Problem | Sehyeog Kim</title>
  <link rel="stylesheet" href="../../../../assets/css/style.css">
</head>
<body>
  <header class="mobile-header">
    <span class="site-title">Sehyeog Kim</span>
    <button class="menu-toggle" aria-label="Menu">&#9776;</button>
  </header>
  <div class="sidebar-overlay"></div>

  <div class="site-wrapper">
    <aside class="sidebar">
      <div class="sidebar-bg">
        <img src="../../../../assets/images/bg.jpg" alt="Background" onerror="this.style.display='none'">
      </div>
      <div class="sidebar-profile">
        <img class="profile-photo" src="../../../../assets/images/profile.jpg" alt="Sehyeog Kim"
             onerror="this.style.background='#eaeef2'">
        <h1 class="profile-name">Sehyeog Kim</h1>
        <p class="profile-bio">AI &amp; Computational Engineering<br>Personal Blog</p>
        <div class="profile-links">
          <a href="https://github.com/Sehyeogkim" target="_blank" rel="noopener">
            <svg viewBox="0 0 16 16" width="15" height="15" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg> GitHub
          </a>
        </div>
      </div>
      <nav class="sidebar-nav">
        <a href="/" class="nav-item nav-home">Home</a>
        <span class="nav-group-label">AI</span>
        <a href="/blog/ai/agentic-ai-theory/" class="nav-item">Agentic_AI_Theory<span class="nav-post-count">8</span></a>
        <a href="/blog/ai/deep-learning/" class="nav-item">Deep-learning<span class="nav-post-count">14</span></a>
        <a href="/blog/ai/machine-learning/" class="nav-item">Machine_Learning<span class="nav-post-count">11</span></a>
        <a href="/blog/ai/sensitivity-analysis/" class="nav-item">Sensitivity_Analysis<span class="nav-post-count">3</span></a>
        <span class="nav-group-label">BioMechanics</span>
        <a href="/blog/biomechanics/blood-flow-and-metabolism/" class="nav-item">Blood-Flow-and-Metabolism<span class="nav-post-count">12</span></a>
        <a href="/blog/biomechanics/cardiovascular-diseases/" class="nav-item">CardioVascular_Diseases<span class="nav-post-count">8</span></a>
        <span class="nav-group-label">Mechanical_Engineering</span>
        <a href="/blog/mechanical-engineering/computational-linear-algebra/" class="nav-item active">Computational-Linear-Algebra<span class="nav-post-count">15</span></a>
        <a href="/blog/mechanical-engineering/computational-fluid-dynamics/" class="nav-item">Computational_Fluid_Dynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/continuum-mechanics/" class="nav-item">Continuum-Mechanics<span class="nav-post-count">9</span></a>
        <a href="/blog/mechanical-engineering/engineering-mathematics/" class="nav-item">Engineering_Mathematics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/finite-element-method/" class="nav-item">Finite-Element-Method<span class="nav-post-count">1</span></a>
        <a href="/blog/mechanical-engineering/fluid-mechanics/" class="nav-item">Fluid_Mechanics<span class="nav-post-count">18</span></a>
        <a href="/blog/mechanical-engineering/gas-dynamics/" class="nav-item">Gas_Dynamics<span class="nav-post-count">24</span></a>
        <a href="/blog/mechanical-engineering/heat-transfer/" class="nav-item">Heat-transfer<span class="nav-post-count">8</span></a>
        <a href="/blog/mechanical-engineering/solid-mechanics/" class="nav-item">Solid_Mechanics<span class="nav-post-count">25</span></a>
        <a href="/blog/mechanical-engineering/thermodynamics/" class="nav-item">Thermodynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/viscous-flow/" class="nav-item">Viscous_Flow<span class="nav-post-count">28</span></a>
      </nav>
    </aside>

    <main class="main-content">
      <div class="breadcrumb"><a href="/">Home</a><span class="sep">/</span><a href="/blog/mechanical-engineering/">Mechanical_Engineering</a><span class="sep">/</span><a href="/blog/mechanical-engineering/computational-linear-algebra/">Computational-Linear-Algebra</a><span class="sep">/</span><span>3. Least Square Problem</span></div>
<a href="/blog/mechanical-engineering/computational-linear-algebra/" class="back-link">&larr; Back to Computational-Linear-Algebra</a>
<div class="page-header"><h1>3. Least Square Problem</h1></div>
<div class="post-meta"><span class="meta-item"><span class="meta-label">Date:</span> 2025-09-06</span><span class="meta-item"><span class="meta-label">Category:</span> Computational-Linear-Algebra</span><span class="meta-item"><span class="meta-label">Source:</span> <a href="https://jeffdissel.tistory.com/225" target="_blank" rel="noopener">link</a></span></div>
<article class="post-content"><p>다시 우리가 무엇을 하고 있는 지를 짚고 넘어가자.<br />
우리는 밑의 선형 행렬방정식을 풀고자 한다.<br />
Linear Matrix Equation.<br />
<img alt="3. Least Square Problem" src="./images/img-001.png" /><br />
실제 공학문제에서 A는 1 million x 1 million 의 dimension을 가지기 때문에,<br />
연산이 굉장히 오래걸리므로, 컴퓨터로 연산해야한다.<br />
하지만, floating problem (컴퓨터에서 저장할 수 있는 소숫점 자리수의 한계)<br />
로 인해서 딱 정확한 해를 구하기는 어렵다.<br />
따라서, 우리는 위 방정식의 Error를 r벡터로 표기하고,<br />
r의 norm을 최소화하는 문제로 전환한다.<br />
<img alt="3. Least Square Problem" src="./images/img-002.png" /><br />
위 새롭게 정의된 문제가 바로,<br />
Least Square Problem이다.<br />
<img alt="3. Least Square Problem" src="./images/img-003.png" /><br />
위 문제를 우리가 지금까지 배웠던<br />
Projection<br />
의 개념을 이용해서,<br />
재해석할 필요가 있다.<br />
Ax = b를 다시 해석해보면,<br />
<img alt="3. Least Square Problem" src="./images/img-004.png" /><br />
range(A) 의 기저벡터들의 선형결합으로 b벡터를 표현하고 싶고,<br />
<img alt="3. Least Square Problem" src="./images/img-005.png" /><br />
그 선형결합 계수가 바로 x 벡터 라는것.<br />
<img alt="3. Least Square Problem" src="./images/img-006.png" /><br />
(굉장히 중요한 개념이다, 꼭 이해해야한다)<br />
문제는<br />
b가 range(A)위에 정확히 있지 않는 경우<br />
가 문제이다.<br />
그렇기 때문에 우리는<br />
벡터 b를 range(A)에 Projection하여,<br />
Pb로 강제로 Projection을 진행해준다.<br />
(P는 이전시간에 배웠던, Projector)<br />
<img alt="3. Least Square Problem" src="./images/img-007.png" /><br />
즉, b를 range(A)위의 벡터와 그렇지 않은(orthogonal한)<br />
벡터로 쪼개주고,<br />
<img alt="3. Least Square Problem" src="./images/img-008.png" /><br />
null(A) 에 존재하는 = range(A)에 Orthogonal 한 벡터를<br />
Residual vector: r로 정의한다.<br />
<img alt="3. Least Square Problem" src="./images/img-009.png" /><br />
결국, Least Square Problem을 재해석하면,<br />
"we wanna find the x that minimizes the Residual vector(r), which is orthogoanl to the range(A)"<br />
<img alt="3. Least Square Problem" src="./images/img-010.png" /><br />
수학적으로, r이 존재할 수 있는 공간을 정의해주자.<br />
range(A)자 존재하는 space Cm안에 존재하는 subset : S라고 정의하면,<br />
우리가 관심있는<br />
subset은 Orthogonal to S<br />
<img alt="3. Least Square Problem" src="./images/img-011.png" /><br />
이제, 해의 갯수를 살펴보자.<br />
linear algebra시간에 다루었다 싶이, rank(A)에 따라서<br />
해가 유일히 존재하는지 수많이 존재하는 지를 우리는 알 수 있다.<br />
<img alt="3. Least Square Problem" src="./images/img-012.png" /><br />
여기서 재밌는 사실은<br />
A<em>를 Least Square Problem 양변에 곱해주면, 다음과 같이 식을 변형 할 수 있다.<br />
<img alt="3. Least Square Problem" src="./images/img-013.png" /><br />
<img alt="3. Least Square Problem" src="./images/img-014.png" /><br />
이렇게 강제로 곱해준 이유는 바로,<br />
Choleksy Factorization<br />
을 사용할 수 있기 때문!.<br />
(A</em>A = R<em>R )<br />
<img alt="3. Least Square Problem" src="./images/img-015.png" /><br />
A</em>A = R<em>R 로 되는 이유는????<br />
어떤 다음과 같은 행렬이 있다고 하자.<br />
<img alt="3. Least Square Problem" src="./images/img-016.png" /><br />
<img alt="3. Least Square Problem" src="./images/img-017.png" /><br />
<img alt="3. Least Square Problem" src="./images/img-018.png" /><br />
<img alt="3. Least Square Problem" src="./images/img-016.png" /><br />
<img alt="3. Least Square Problem" src="./images/img-017.png" /><br />
<img alt="3. Least Square Problem" src="./images/img-018.png" /><br />
위 행렬은 위와 같이 Right and Left triangular Matrix로 분해가 가능하다.<br />
그렇다면 모든 행렬이 분해가 가능한게 아닐텐데???<br />
어떤 녀석들만??? 바로<br />
Hermitian Positive Definite Matrix<br />
<img alt="3. Least Square Problem" src="./images/img-019.png" /><br />
위 두가지 조건을 만족하는 모든 행렬은 분해가 가능하다는 것!!.<br />
따라서, 우리가 A</em>를 곱해준 이유는 바로,<br />
<img alt="3. Least Square Problem" src="./images/img-020.png" /><br />
A<em>A가 무조건 Hermitian Positive semi Defintie Matrix이기 때문이다.<br />
따라서, 강제로 Hermitian Positive Definite Matrix로 만들어주고,<br />
Cholesky 분해로 간단한 R로 재 분해 해주어서,<br />
풀기 쉬운 형태로 방정식을 만들어주는게, 아래알고리즘의 원리.<br />
<img alt="3. Least Square Problem" src="./images/img-021.png" /><br />
또 다른 방법으로는,<br />
<img alt="3. Least Square Problem" src="./images/img-020.png" /><br />
(normal Equation)<br />
A</em>A는 Positive Definite Matrix이므로 역행렬이 무조건 존재한다.<br />
따라서, 우리가 다음과 같이 A+: Pseudoinverse of A 를 만들어 줄 수 있다<br />
<img alt="3. Least Square Problem" src="./images/img-022.png" /><br />
결국 우리가 풀고자 하는 문제를,<br />
다음과 같이 재 표현 할수 있고 비교적 쉽게 x를 구할 수가 있다는 것.<br />
<img alt="3. Least Square Problem" src="./images/img-023.png" /><br />
=========================================<br />
마지막으로, 큰 흐름을 이해가 넘어가자<br />
우리는 밑의 선형 행렬방정식을 풀고자 한다.<br />
<img alt="3. Least Square Problem" src="./images/img-001.png" /><br />
그런데 실제로는 computational float문제, noise 문제로 인해서<br />
Least square Problem으로 전환하였다.<br />
<img alt="3. Least Square Problem" src="./images/img-002.png" /><br />
여기서 문제를 보다 쉽게 풀기 위해 A = QR로 분해한후 위 문제를 해결 할수 있고,<br />
혹은 Cholesky Factorization을 사용할 수 도 있다.<br />
<img alt="3. Least Square Problem" src="./images/img-024.png" /><br />
Normal equation method via Cholesky Factorizaiton.<br />
(여기서 주의할 점은<br />
A<em> A 를 구성하는게,<br />
numerical issue를 발생할 수 가 있다.<br />
이런 경우는 QR 분해를 실행하는게 더 안정정.)<br />
A</em> A 를 구성하는게 Numerical error 가 증폭되는 A를<br />
ill conditioned Matrix 라고 부르고,<br />
이를 판단하는 기준이 바로 condition number<br />
(추후에 자세히 다룰 예정)<br />
또한,<br />
A - sparse Matrix (요소에 0이 많이 존재하는 경우)<br />
--&gt; QR factorizaiton ( computational effective)</p></article>
      <footer class="site-footer">
        <p>&copy; 2026 Sehyeog Kim</p>
      </footer>
    </main>
  </div>
  <script src="../../../../assets/js/main.js"></script>
</body>
</html>