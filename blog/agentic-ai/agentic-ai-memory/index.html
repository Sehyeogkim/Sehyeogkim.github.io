<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>🎐 Agentic AI - Memory | Sehyeog Kim</title>
  <link rel="stylesheet" href="../../../assets/css/style.css">
</head>
<body>
  <!-- Mobile header -->
  <header class="mobile-header">
    <span class="site-title">Sehyeog Kim</span>
    <button class="menu-toggle" aria-label="Menu">&#9776;</button>
  </header>
  <div class="sidebar-overlay"></div>

  <div class="site-wrapper">
    <!-- Sidebar -->
    <aside class="sidebar">
      <div class="sidebar-bg">
        <img src="../../../assets/images/bg.jpg" alt="Background"
             onerror="this.style.display='none'">
      </div>
      <div class="sidebar-profile">
        <img class="profile-photo"
             src="../../../assets/images/profile.jpg"
             alt="Sehyeog Kim"
             onerror="this.style.background='#21262d'">
        <h1 class="profile-name">Sehyeog Kim</h1>
        <p class="profile-bio">AI &amp; Computational Engineering<br>Knowledge Base</p>
        <div class="profile-links">
          <a href="https://github.com/Sehyeogkim" target="_blank" rel="noopener">
            <svg viewBox="0 0 16 16" width="16" height="16" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg> GitHub
          </a>
        </div>
      </div>
      <nav class="sidebar-nav">
        <a href="/" class="nav-item nav-home">Home</a>
        <span class="nav-label">Categories</span>
        <a href="/blog/advanced-engineering-mathematics/" class="nav-item">Advanced_Engineering_Mathematics<span class="nav-post-count">14</span></a>
        <a href="/blog/agentic-ai/" class="nav-item active">Agentic_AI<span class="nav-post-count">8</span></a>
        <a href="/blog/blood-flow-and-metabolism/" class="nav-item">Blood-Flow-and-Metabolism<span class="nav-post-count">12</span></a>
        <a href="/blog/cardiovascular-diseases/" class="nav-item">CardioVascular_Diseases<span class="nav-post-count">8</span></a>
        <a href="/blog/computational-linear-algebra/" class="nav-item">Computational-Linear-Algebra<span class="nav-post-count">15</span></a>
        <a href="/blog/continuum-mechanics/" class="nav-item">Continuum-Mechanics<span class="nav-post-count">9</span></a>
        <a href="/blog/deep-learning/" class="nav-item">Deep-learning<span class="nav-post-count">14</span></a>
        <a href="/blog/finite-element-method/" class="nav-item">Finite-Element-Method<span class="nav-post-count">1</span></a>
        <a href="/blog/fluid-mechanics/" class="nav-item">Fluid_Mechanics<span class="nav-post-count">18</span></a>
        <a href="/blog/gas-dynamics/" class="nav-item">Gas_Dynamics<span class="nav-post-count">24</span></a>
        <a href="/blog/heat-transfer/" class="nav-item">Heat-transfer<span class="nav-post-count">8</span></a>
        <a href="/blog/machine-learning/" class="nav-item">Machine_Learning<span class="nav-post-count">11</span></a>
        <a href="/blog/numerical-heat-transfer-and-fluid-flow/" class="nav-item">Numerical-Heat-transfer-and-Fluid-flow<span class="nav-post-count">14</span></a>
        <a href="/blog/sensitivity-analysis/" class="nav-item">Sensitivity_Analysis<span class="nav-post-count">3</span></a>
        <a href="/blog/solid-mechanics/" class="nav-item">Solid_Mechanics<span class="nav-post-count">25</span></a>
        <a href="/blog/thermodynamics/" class="nav-item">Thermodynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/viscous-flow/" class="nav-item">Viscous_Flow<span class="nav-post-count">28</span></a>
      </nav>
    </aside>

    <!-- Main content -->
    <main class="main-content">
      <div class="breadcrumb">  <a href="/">Home</a><span class="sep">/</span>  <a href="/blog/agentic-ai/">Agentic_AI</a><span class="sep">/</span>  <span>🎐 Agentic AI - Memory</span></div>
<a href="/blog/agentic-ai/" class="back-link">&larr; Back to Agentic_AI</a>
<div class="page-header"><h1>🎐 Agentic AI - Memory</h1></div>
<div class="post-meta"><span class="meta-item"><span class="meta-label">Date:</span> 2026-02-24</span><span class="meta-item"><span class="meta-label">Category:</span> Agentic_AI</span><span class="meta-item"><span class="meta-label">Source:</span> <a href="https://www.notion.so/3102a46dc68c8018a4cfc41d9819372f" target="_blank" rel="noopener">link</a></span></div>
<article class="post-content"><p>목차<br />
- Frontend framework: 사용자가 대화/작업을 요청하는 UI (part1)<br />
- Agent development framework: 에이전트 로직(루프, 상태, 도구 연결)을 만드는 프레임워크  (part1)<br />
- <span color="red"><strong>Agent memory: 대화/세션 상태와 장기 기억 저장 (part1)</strong></span><br />
- Agent tools: 검색, DB, 사내 API 등 “행동”을 수행하는 도구 묶음 (part1)<br />
- Agent design patterns: 싱글 에이전트 vs 멀티 에이전트 등 구조 패턴 (part3)<br />
- Agent runtim: 에이전트 애플리케이션이 실제로 돌아가는 실행 환경 (part3)<br />
- AI models: 추론/의사결정 엔진(part 3)<br />
- Model runtime: 모델을 서빙하는 인프라(관리형 API/컨테이너/GKE 등) (part 3)</p>
<p><img alt="🎐 Agentic AI - Memory" src="./images/img-001.png" /></p>
<p>Agentic AI를 한 문장으로 정리하면, <strong>사용자 의도를 이해하고 → 여러 단계 계획을 세우고 → 도구를 호출해 실행까지 끝내는</strong> 자율 시스템이다. 단순히 “답변을 생성하는 모델”이 아니라, <strong>계획(Planning)</strong> 과 <strong>도구(Tools)</strong> 를 통해 실제 업무를 완료하도록 설계된 아키텍처인 것이다.<br />
이 작업을 진행하기 위해서는, 이전에 어떤 비슷한 작업을 했는지, 사용자의 특성은 무엇인지를 agent가 미리 인지하고 작업을 하는것이 효율적이고 이를 위해 Memory기능은 필수적이다.<br />
<img alt="🎐 Agentic AI - Memory" src="./images/img-002.png" /><br />
(agent memory 기능이 없다면 위 예시처럼, action, operation과정이 계속해서 늘어나고, 진행이 느려지는 상황이 발생한다)</p>
<h1>단기기억</h1>
<hr />
<p>Agent memory는 사람의 기억과도 같다. 우리가 어떤 사람과 대화를 진행할때, 그 사람과의 대화 흐름과 내용을 기억을 하지만, 장기적으로는 모든 대화내용을 기억할 수는 없다. <br />
(사람들의 뇌에 저장공간의 한계가 있기 때문이다). </p>
<p>우리가 CHATGPT를 사용하면, 경험에 의해서 아마 모든 분들이 아실 것이다. 새로운 대화창을 열게 되면, 기존에 대화했던 것들과 별개의 내용에 대해서 이야기 할 수 있다. 즉, 대화 기억이 reset되는 것이다. </p>
<p>여기서 중요한 개념 두개를 짚고 넘어가자. <br />
1. Session: 사용자와 에이전트가 주고받는 “대화창”<br />
    - 한 세션 안에서는 이전 메세지들이 이어진 맥락으로 (단기기억으로) 기억됨.<br />
    - 한 세션은 다른 세션 내용과 섞이지 않음, 다른말로 다른 세션을 기억하지 않음.<br />
2. State: 한 session에서 대화를 통해 정리된 “현재 작업의 핵심 정보” <br />
    - state type: 목표 제약, 이미 결정된 사항, 진행단계, 다음 행동 같은 구조화된 요약.</p>
<p><img alt="🎐 Agentic AI - Memory" src="./images/img-003.png" /></p>
<p>위 Chatpgt history에서 session은<br />
- Opencalw Voice call 설정<br />
- Twill Definition and Uses<br />
- Openclaw 전화설정<br />
- etc.<br />
state는<br />
- 사용자의 목표: “푸꾸옥 공항 짐 보관 위치/가격 조사”<br />
- 제약조건: “한국어로 요약, 가격 비교 포함”<br />
- 이미 결정된 선택: “후보는 피크타임 우선”<br />
- 현재 진행 단계: “1) 후보 리스트업 완료 → 2) 가격/위치 검증 단계”<br />
- 해야 할 다음 행동: “구글맵 위치 확인 / 최신 후기 3개 요약”<br />
- 도구 사용 결과 요약: “검색 결과 핵심만 5줄로 정리”</p>
<p>여기서 굉장히 중요한 점은 두가지이다:<br />
- <strong>“단기기억은 ‘Session에서’ 맥락을 유지하기 위해 시스템이 관리하는 대화/상태(state)이다.”</strong><br />
- <strong>“LLM 자체가 기억하는 것이 아니라, 대화 기록/상태를 컨텍스트로 재주입해서 기억하는 것처럼 동작한다.”</strong><br />
- <strong>대화내용을 ‘문자’로 전부 기억하는 것은 비효율 적이므로, 핵심적인 state를 중심으로 기억한다.</strong><br />
위 사진의 예시에서, <strong><code>‘openclaw voice call 설정’ session</code></strong>내부에서 대화내용을 계속해서 기억하는 능력이 바로 단기기억능력인 것이다.  </p>
<p>재미 있는 사실은 LLM이 기억을 하는게 아니라 openai, antropic, google 모든 회사들이 아래의 구조로 설계를 해서 그렇다.</p>
<p>들어가기전에 context window라는 개념을 빠르게 짚고 넘어가자. 컨텍스트 윈도우(Context Window)는 <span color="red"><strong>“대형 언어 모델(LLM)이 한 번의 대화나 작업에서 이해하고 기억할 수 있는 최대 입력 및 출력 텍스트의 양” 이다.</strong></span><br />
아래의 LLM에 넣어주는 prompt를 보면 words, imsage, videos가 있다. 하지만 LLM 이 현재 감당할 수 있는 최대 양이 존재를 한다. <br />
<img alt="🎐 Agentic AI - Memory" src="./images/img-004.png" /></p>
<p>아래 2026.02자료에 따르면 Claude, gpt-codex의 context window는 1M, 400K token이라고 적혀 있다. 여기서 토큰은, 우리가 prompt에 입력하는 데이터의 종류는 (글, 이미지, 비디오)로 다양하지만 이를 LLM이 흡수할때는 하나의 데이터이다. 따라서, 공통된  단위를 사용하고 그 단위가 token이다. 다시 말해서, LLM이 흡수하는 데이터의 단위이다.<br />
(쉽게 말해 글을 많이 쓰고, 이미지를 많이 쓰고, 비디오의 용량이 크다면, 사용되는 토큰이 많다 라고 이해하시면 좋다.)</p>
<p><img alt="🎐 Agentic AI - Memory" src="./images/img-005.png" /><br />
[Nivida blog]<br />
“LLM (Large Language Model) token is <strong>the fundamental unit of text or code that a model processes, analyzes, and generates</strong>. Think of tokens as the "Lego bricks" of language—they are the basic pieces used to break down input text into manageable units before converting them into numerical representations (vectors)”</p>
<hr />
<p>다시 chatgpt가 어떻게 대화창의 이전 내용들을 기억하는가? 라는 질문으로 돌아가 보면, context window 즉 입력해주는 prompt 내부에 이전 대화내용들을 짚어 넣는 것이다.아래의 사진을 보면 turn2,3에서는 turn1,2 즉 이전 대화의 내용들을 같이 짚어 넣는다.(사용자의 질문과 답변까지 짚어 넣는다).<br />
<img alt="🎐 Agentic AI - Memory" src="./images/img-006.png" /></p>
<p>하지만, 이야기 했다 싶이. context window의 제한 위 사진에서는 200k token이 존재한다. 따라서, 모든 대화를 넣을 수 없다. 그래서 openai docs에 따르면 두가지 방식 을 사용한다.<br />
<a href="https://developers.openai.com/cookbook/examples/agents_sdk/session_memory/?utm_source=chatgpt.com">Context Engineering - Short-Term Memory Management with Sessions from OpenAI Agents SDK</a></p>
<h3>Trimming</h3>
<hr />
<p>Trimming은 아주 단순하게 time sequence에 따라 대화내용을 정렬한후, context window한계치까지만 담는 것이다. (이전 내용은 다 지우는 것)<br />
<img alt="🎐 Agentic AI - Memory" src="./images/img-007.png" /></p>
<h3>Compaction</h3>
<hr />
<p>Compact (summarizing)은 대화내용들을 전부 요약한다음에 하나의 compaction block으로 create한 후에, Context window에 짚어 넣어 이후 대화를 진행하는 것이다.<br />
<a href="https://platform.claude.com/docs/en/build-with-claude/compaction">Compaction</a></p>
<p><img alt="🎐 Agentic AI - Memory" src="./images/img-008.png" /></p>
<h1>장기기억</h1>
<hr />
<p>단기기억이 “한 세션 안에서 유지되는 대화/상태(state)”라면, 장기기억은 세션이 바뀌어도 계속 남아있는 ‘지속 저장(persistent storage)’이다. 즉, 에이전트가 매번 처음부터 다시 묻고 배우지 않도록, <strong>사용자 선호·프로젝트 지식·과거 결정사항·자주 쓰는 문서</strong> 등을 저장해두고 필요할 때 꺼내 쓰는 구조다.</p>
<h3>wHY?</h3>
<hr />
<p>위에서 설명했다 싶이, 컨텍스트 윈도우는 결국 제한이 있기 때문에, 대화가 길어지면 길어질수록 (요약, trim)으로 <strong>“모든 것을 대화 히스토리로 들고 가는 방식”은 오래 못 간다.</strong> 그래서 장기기억이 필요해진다.<br />
- <strong>개인화:</strong> 사용자의 말투/선호/목표를 기억해서 매번 설명을 반복하지 않게 한다.<br />
- <strong>지식 유지:</strong> 프로젝트의 배경지식, 내부 문서, 과거 결정사항을 축적해 “업무 연속성”을 만든다.<br />
- <strong>정확성/근거:</strong> 모델이 학습 때 보지 못한 최신 정보나 사내 정보를, 저장소에서 찾아와 답변을 “grounding(근거화)”한다.<br />
- <strong>비용/속도:</strong> 긴 대화 전체를 넣는 대신, 필요한 것만 검색해 넣으면 토큰 비용과 지연이 줄어든다. (RAG의 대표 장점)</p>
<h3>Method</h3>
<hr />
<p>장기기억은 “외부 저장소 + 검색/회수(retrieval)”로 구현되는 경우가 많다. 크게 3갈래가 실무에서 많이 쓰인다.</p>
<h3>(A) 파일 기반 메모리 (가장 단순·직관)</h3>
<p>아래 context engineering의 예시를 보면, 사실 우리가 agent에게 “오늘 날씨가 어때” 라고 질문을 한다면, 단순히 그 질문만 LLM(뇌)에 들어 가는게 아니라, 현재 가지고 있는 도구들그리고 기억도 같이 prompt에 들어간다. 따라서, 우리는 <code>memory.md</code>파일에 장기기억해야할 내용들을 자연어로 작성하고, prompt에 넣어준다.( Application단계에서 설명드리겠지만, <code>memory.md</code>의 내용을 자동으로 읽게 할 수도 있고, 수동으로 파일의 위치를 질문할때 알려 줄수도 있다.)<br />
-  장점: 자연어로 적기만 하면 되니, 구현이 쉽고, 사람이 직접 열어보고 수정할 수 있어 디버깅이 편하다.<br />
- 한계: 규모가 커지면 “필요한 부분만 빠르게 찾기”가 어려워진다. (결국에 또다른 context이므로, 많이 쓸수가 없다)<br />
<img alt="🎐 Agentic AI - Memory" src="./images/img-009.png" /></p>
<h3>Claude memory</h3>
<p>실제 Claude code docx (<a href="https://code.claude.com/docs/en/memory#how-it-works">Manage Claude's memory - Claude Code Docs</a>)를 살펴보면, session의 맨 처음에 200줄의 <code>memory.md</code>내용이 자동 기입된다고 말한다. 즉 모든 대화에서 memory.md를 넣으면 비효율적이니 session의 처음에 기입한다.<br />
<img alt="🎐 Agentic AI - Memory" src="./images/img-010.png" /></p>
<h3>(B) 벡터 DB(Vector Database) / 임베딩 검색</h3>
<p>(<a href="https://mehmetozkaya.medium.com/exploring-vector-databases-pinecone-chroma-weaviate-qdrant-milvus-pgvector-and-redis-f0618fe9e92d">Exploring Vector Databases: Pinecone, Chroma, Weaviate, Qdrant, Milvus, PgVector, and Redis</a>)<br />
<img alt="🎐 Agentic AI - Memory" src="./images/img-011.png" /></p>
<p>자 두번째로, 외부 저장공간을 이용하는 memory 장기기억 방식이다. 위사진을 보게 되면, 다양한 <strong>제품/오픈소스 프로젝트</strong>가 존재한다. y축은 상업/open source 로 구분이 되어 있으며, 위쪽은 <strong>Dedicated = 벡터 검색이 주업(전용 엔진)</strong>, <strong>Support = 본업은 따로 있고 벡터 검색은 옵션(추가 기능) 로 이해하면 된다.</strong></p>
<p>“RAG는 ‘외부 지식을 검색해(주로 벡터 검색) LLM 입력에 붙인 뒤 생성하는’ 패턴이다. 벡터 DB는 RAG에서 가장 널리 쓰이는 retrieval 저장소 중 하나다.”</p>
<h3>Retrieval Augmented Generation (RAG) Process</h3>
<hr />
<p><img alt="🎐 Agentic AI - Memory" src="./images/img-012.png" /><br />
<a href="https://medium.com/enterprise-rag/an-introduction-to-rag-and-simple-complex-rag-9c3aa9bd017b">An introduction to RAG and simple/ complex RAG</a></p>
<p>사용자에게 질문을 받기 전에, 먼저 Vector Database를 구축해야한다. 이해를 위해서, 병원에서 사용하는 RAG라고 가정하자.<br />
- A: Raw Data Source<br />
    - e.g) 환자의 데이터와 치료 방식들이 담긴 문서들을 준비한다.<br />
- B: Information Extraction<br />
    - (방대한 데이터) → 검색 가능한 텍스트/meta data를 뽑아냄 (pdf → text, image → text)<br />
    - 환자의 진단 결과 데이터 medical image → text, pdf → text로 전부 전환한다.<br />
- C: Chunking<br />
    - pdf, 문서 → 문단, 섹션/소제목 단위<br />
    - 전환된 정보를 의미있는 더 작은 덩어이로 쪼갠다. (너무 크면 context window에 들어가지 못함) <br />
- Embedding<br />
    - chunk → embedding vector (벡터화진행)<br />
    - e.g) 환자 정보, 진단 정보 덩어리들을 벡터화(숫자로 나타냄) 그리고 database에 짚어 넣는다.</p>
<h3>Example (RAG + LLM)</h3>
<p>사용자가 질문을 하면, 시스템은 <strong>질문 전체를 임베딩(벡터화)</strong> 하고 벡터 DB에서 <strong>의미적으로 가장 가까운 chunk(top-k)</strong> 를 검색한다. 그리고 검색된 chunk의 원문(및 메타데이터)을 <strong>컨텍스트 윈도우에 첨부</strong>한 뒤, LLM이 그 근거를 바탕으로 답변을 생성하도록 한다.<br />
1. 사용자가 질문을 함. <br />
    e.g.) “이 환자 케이스에서 <strong>참고해야 할 프로토콜/주의사항을 근거와 함께 정리해줘</strong>”<br />
2. 환자 요약(진단명/검사결과/금기/과거력)을 구조화해서 쿼리로 만든다<br />
3. 병원 내부 지식베이스(치료 프로토콜, 가이드라인, 약물 금기 목록, 유사 케이스 요약)에서 top-k 문서를 검색 후, 검색된 근거 문서의 핵심 문단을 컨텍스트에 붙인다<br />
4. LLM이 “근거 문서 기반으로 가능한 옵션/주의사항/추가로 확인할 정보”를 정리한다<br />
5. 사용자에게 답변을 진행.</p>
<ul>
<li>장점: 문서를 “의미 기반”으로 찾을 수 있어, 키워드가 정확히 일치하지 않아도 관련 내용을 잘 끌어온다. RAG에서 가장 흔한 저장소 타입이다.</li>
</ul>
<h1>Conclusion</h1>
<p><a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents?utm_source=chatgpt.com">Effective context engineering for AI agents</a><br />
<img alt="🎐 Agentic AI - Memory" src="./images/img-013.png" /></p>
<p>마무리로, antropic (claude)의 context window를 살펴보고 마무리하자. 결국 기억을 하려면 prompt에 입력을 해주어야 한다. 따라서 prompt engineering이라는 좌측의 용어도 존재한다. “프롬트를 어떻게 쓰고, 조작하는지”</p>
<p>하지만 agentic ai시대에서 사용해야할 tool, 기억해야할 memory는 많아지고 context window는 한정적이므로, 어떠한 조합으로 tool, memory들을 최소한으로 넣어서 최대한의 효율적인 action을 할 수 있을까? 라는 context engineering을 antropic은 새롭게 정의한다.</p>
<h3>재미있는 사실: 너무 많이 짚어 넣어도 분산된다.</h3>
<hr />
<p>글은 컨텍스트를 <strong>“무한히 넣으면 좋다”가 아니라, 넣을수록 집중력이 떨어질 수 있는 자원</strong>으로 봅니다.<br />
- 토큰이 늘수록 모델이 중요한 정보를 잘 못 집어내는 <strong>context rot(문맥 부패)</strong> 같은 현상이 관찰된다고 언급합니다.<br />
- 근본 이유는 트랜스포머가 토큰들 사이의 관계를 모두 보려다 보니(상호 attention), 길어질수록 “주의(Attention) 예산”이 얇아진다는 설명을 합니다.<br />
그래서 목표는 “가장 작은 토큰으로 가장 높은 신호(signal)를 만들기”입니다<br />
<img alt="🎐 Agentic AI - Memory" src="./images/img-014.png" /><br />
이번시간에는 저 context window에서 memory 부분은 어디서 가져와서 채워넣는지. DOC1,2는 유저의 database에서 어떻게 가져오는지에 대해서 알아보았다.</p>
<p>→ 다음 시간은 tool에 대해서 살펴보자.</p></article>
      <footer class="site-footer">
        <p>&copy; 2026 Sehyeog Kim. Built with gitfolio-inspired theme.</p>
      </footer>
    </main>
  </div>

  <script src="../../../assets/js/main.js"></script>
</body>
</html>