<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>🎐 Agentic AI - tools | Sehyeog Kim</title>
  <link rel="stylesheet" href="../../../assets/css/style.css">
</head>
<body>
  <!-- Mobile header -->
  <header class="mobile-header">
    <span class="site-title">Sehyeog Kim</span>
    <button class="menu-toggle" aria-label="Menu">&#9776;</button>
  </header>
  <div class="sidebar-overlay"></div>

  <div class="site-wrapper">
    <!-- Sidebar -->
    <aside class="sidebar">
      <div class="sidebar-bg">
        <img src="../../../assets/images/bg.jpg" alt="Background"
             onerror="this.style.display='none'">
      </div>
      <div class="sidebar-profile">
        <img class="profile-photo"
             src="../../../assets/images/profile.jpg"
             alt="Sehyeog Kim"
             onerror="this.style.background='#21262d'">
        <h1 class="profile-name">Sehyeog Kim</h1>
        <p class="profile-bio">AI &amp; Computational Engineering<br>Knowledge Base</p>
        <div class="profile-links">
          <a href="https://github.com/Sehyeogkim" target="_blank" rel="noopener">
            <svg viewBox="0 0 16 16" width="16" height="16" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg> GitHub
          </a>
        </div>
      </div>
      <nav class="sidebar-nav">
        <a href="/" class="nav-item nav-home">Home</a>
        <span class="nav-label">Categories</span>
        <a href="/blog/advanced-engineering-mathematics/" class="nav-item">Advanced_Engineering_Mathematics<span class="nav-post-count">14</span></a>
        <a href="/blog/agentic-ai/" class="nav-item active">Agentic_AI<span class="nav-post-count">8</span></a>
        <a href="/blog/blood-flow-and-metabolism/" class="nav-item">Blood-Flow-and-Metabolism<span class="nav-post-count">12</span></a>
        <a href="/blog/cardiovascular-diseases/" class="nav-item">CardioVascular_Diseases<span class="nav-post-count">8</span></a>
        <a href="/blog/computational-linear-algebra/" class="nav-item">Computational-Linear-Algebra<span class="nav-post-count">15</span></a>
        <a href="/blog/continuum-mechanics/" class="nav-item">Continuum-Mechanics<span class="nav-post-count">9</span></a>
        <a href="/blog/deep-learning/" class="nav-item">Deep-learning<span class="nav-post-count">14</span></a>
        <a href="/blog/finite-element-method/" class="nav-item">Finite-Element-Method<span class="nav-post-count">1</span></a>
        <a href="/blog/fluid-mechanics/" class="nav-item">Fluid_Mechanics<span class="nav-post-count">18</span></a>
        <a href="/blog/gas-dynamics/" class="nav-item">Gas_Dynamics<span class="nav-post-count">24</span></a>
        <a href="/blog/heat-transfer/" class="nav-item">Heat-transfer<span class="nav-post-count">8</span></a>
        <a href="/blog/machine-learning/" class="nav-item">Machine_Learning<span class="nav-post-count">11</span></a>
        <a href="/blog/numerical-heat-transfer-and-fluid-flow/" class="nav-item">Numerical-Heat-transfer-and-Fluid-flow<span class="nav-post-count">14</span></a>
        <a href="/blog/sensitivity-analysis/" class="nav-item">Sensitivity_Analysis<span class="nav-post-count">3</span></a>
        <a href="/blog/solid-mechanics/" class="nav-item">Solid_Mechanics<span class="nav-post-count">25</span></a>
        <a href="/blog/thermodynamics/" class="nav-item">Thermodynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/viscous-flow/" class="nav-item">Viscous_Flow<span class="nav-post-count">28</span></a>
      </nav>
    </aside>

    <!-- Main content -->
    <main class="main-content">
      <div class="breadcrumb">  <a href="/">Home</a><span class="sep">/</span>  <a href="/blog/agentic-ai/">Agentic_AI</a><span class="sep">/</span>  <span>🎐 Agentic AI - tools</span></div>
<a href="/blog/agentic-ai/" class="back-link">&larr; Back to Agentic_AI</a>
<div class="page-header"><h1>🎐 Agentic AI - tools</h1></div>
<div class="post-meta"><span class="meta-item"><span class="meta-label">Date:</span> 2026-02-24</span><span class="meta-item"><span class="meta-label">Category:</span> Agentic_AI</span><span class="meta-item"><span class="meta-label">Source:</span> <a href="https://www.notion.so/3112a46dc68c8039bf21ed03f0b6f62d" target="_blank" rel="noopener">link</a></span></div>
<article class="post-content"><p>목차<br />
- Frontend framework: 사용자가 대화/작업을 요청하는 UI (part1)<br />
- Agent development framework: 에이전트 로직(루프, 상태, 도구 연결)을 만드는 프레임워크  (part1)<br />
- Agent memory: 대화/세션 상태와 장기 기억 저장 (part1)<br />
- <span color="red"><strong>Agent tools: 검색, DB, 사내 API 등 “행동”을 수행하는 도구 묶음 (part1)</strong></span><br />
- Agent design patterns: 싱글 에이전트 vs 멀티 에이전트 등 구조 패턴 (part3)<br />
- Agent runtim: 에이전트 애플리케이션이 실제로 돌아가는 실행 환경 (part3)<br />
- AI models: 추론/의사결정 엔진(part 3)<br />
- Model runtime: 모델을 서빙하는 인프라(관리형 API/컨테이너/GKE 등) (part 3)</p>
<p><img alt="🎐 Agentic AI - tools" src="./images/img-001.png" /></p>
<p>Agentic AI를 한 문장으로 정리하면, <strong>사용자 의도를 이해하고 → 여러 단계 계획을 세우고 → 도구를 호출해 실행까지 끝내는</strong> 자율 시스템이다. 단순히 “답변을 생성하는 모델”이 아니라, <strong>계획(Planning)</strong> 과 <strong>도구(Tools)</strong> 를 통해 실제 업무를 완료하도록 설계된 아키텍처인 것이다.</p>
<p>이번시간에는 가장 중요한 도구를 <br />
1. <span color="red"><strong>어떻게 agent가 tool을 사용하는지. </strong></span><br />
2. <span color="red"><strong>사용자는 어떻게 도구를 세팅해야하는지.</strong></span><br />
이 두가지를 중심으로 살펴보자.</p>
<p><strong><code>Claude doc</code></strong>을 중심으로 agentic Ai는 도구를 3가지 방식으로 분류하여 사용한다.<br />
1. <em>Built in client tools</em><br />
2. <em>Built in server tools</em><br />
3. <em>MCP - server tools.</em></p>
<p>사용하는 도구들이 존재하는 저장공간이 다른 것이지 사실 전체적인 processs는 공통적이다.<br />
1. 먼저 LLM이 available tools + prompt(주어진 문제)를 고려해서  지금 상황에 필요한 tool을 (평가)하여 pick한다.<br />
2. 이후에 그 tool을 가지고 perform을 한 후, 결과를 도출하여 response 하는 과정이다.<br />
<img alt="🎐 Agentic AI - tools" src="./images/img-002.png" /></p>
<p>출처: <a href="https://platform.claude.com/docs/en/agents-and-tools/tool-use/overview">Tool use with Claude</a></p>
<h3>1. Built-in client tools.</h3>
<hr />
<p>이 도구는 결국에 사용자가 미리 만들어 놓은 tool이다. 즉, 미리 만들어 놓은 코드이거나, 혹은 AI가 미리 짠 코드. 등등 그저 agent가 함수를 호출하기만 하면 되는 가장 간단한 도구이다.</p>
<h3>Agent가 어떻게 쓰나</h3>
<ul>
<li>Claude(LLM)이 <code>tool_use</code> 형태로 **“이 함수 이름 + 인자(JSON)”**를 출력한다.</li>
<li>내 애플리케이션이 그 호출을 받아 <strong>실제 코드 실행</strong> 후, 결과를 <code>tool_result</code>로 다시 Claude에게 넣어준다. (즉, 실행 책임은 나에게 있음)</li>
</ul>
<h3>사용자는 어떻게 세팅하나</h3>
<ul>
<li><code>tools</code>에 **툴 스키마(이름/설명/입력 JSON schema)**를 등록한다.</li>
<li>“툴 설명은 최소 3–4문장 이상”으로: 언제 쓰는지, 반환 형식, 제약/주의사항까지 적어야 툴 선택 정확도가 오른다. (코드 경로를 알려주면 됨).</li>
</ul>
<h3>2. Built-in server tools</h3>
<hr />
<p>Server tools follow a different workflow where Anthropic's servers handle tool execution in a loop:</p>
<h3>Agent가 어떻게 쓰나</h3>
<ul>
<li>툴 실행 루프를 <strong>Anthropic/openai 서버가 관리</strong>한다. 사용자는 “웹 검색/웹 fetch 등”을 쓰고 싶다고만 주면, 모델이 호출하고 결과가 다시 모델로 들어온다.</li>
</ul>
<h3>사용자는 어떻게 세팅하나</h3>
<ul>
<li>API에서 해당 server tool을 “사용 가능”하게 포함시키고(문서의 요구 파라미터/헤더 포함), 프롬프트에 “검색해줘/이 URL 분석해줘” 같은 요청을 넣는다</li>
</ul>
<p>자 여기까지 tools이 내 local server에 존재하고, 실행도 내 local에서 되는지, 혹은 model 제공하는 antropic/openai/google server에서 실행되는지에 따라서, 두가지로 나뉘었다.<br />
이번에는 전혀 다른 server에서 tool을 가져와 쓰는 MCP server에 대해서 알아보도록 하자.</p>
<p><img alt="🎐 Agentic AI - tools" src="./images/img-003.png" /></p>
<h3>3. MCP server tools.</h3>
<hr />
<p>MCP를 안쓰는 agent AI는 없을 정도로 굉장히 중요하므로, 조금 깊게 들어가 보자. 지금 우리는 도구 조작을 agent가 어떻게 하는지를 살펴보고 있고, 지금까지 인간이 역사적으로 지금까지 만들어 놓은 도구들 google cloud, notion, excel, powerpoint and so on. 등을 조작을 하려면 API 함수를 읽고, 그거에 맞게 코드를 작성해야 (before MCP사진) 우리가 원하는 정보를 주고 받을 수 있었다. <br />
<a href="https://modelcontextprotocol.io/docs/learn/architecture">Architecture overview - Model Context Protocol</a><br />
<img alt="🎐 Agentic AI - tools" src="./images/img-004.png" /></p>
<p>하지만, 이제는 MCP라는 약속된 프롤토콜을 사용함으로 써, 편리해졌다.<br />
뿐만안라 Agent가 사용하는 framework가 CLI, IDE … 다양한데, 그거와 상관없이 모든 framework에서 공통된 MCP로 제어가 가능하다.</p>
<p><img alt="🎐 Agentic AI - tools" src="./images/img-005.png" /></p>
<p>그렇다면, 이제 MCP의 정확히 어떻게 구성되고 작동하는 지를 살펴보자.</p>
<h3>MCP - architecture</h3>
<hr />
<p>먼저 <code>3가지 구성 요소</code>를 기억하자.<br />
1. MCP hosts - Agent AI 가 작동하고, 여러 MCP client를 manage하는 주체.<br />
2. MCP client - 외부 MCP server와 MCP host를 연결하기 위해서, MCP hosts 내부에 서버하나당 매핑되는 객체를 만들고, 그 객체가 바로 MCP client이다.<br />
3. MCP server - MCP client와 소통하는 정보를 주고 받는 외부 program.</p>
<p><img alt="🎐 Agentic AI - tools" src="./images/img-006.png" /></p>
<p>여기서 핵심은 <code>MCP client ↔ MCP server</code>와의 정보를 주고 받는 방식, 그리고 어떤 정보를 주고 받는지 이다.<br />
그 사이에는 data, transport layer이렇게 두가지로 구분할 수 있다. (MCP host는 사용하는 framework에 따라서 openai - codex, visual studio code ID, cursor IDE, claude code… 등 다양하다)</p>
<p>정보를 주고 받기 위한, 구조 두가지는 다음과 같다:<br />
- transport layer<br />
- data layer</p>
<h3>Transport layer</h3>
<hr />
<p><img alt="🎐 Agentic AI - tools" src="./images/img-007.png" /><br />
- stdio : Local 내부 통신을 사용한다. 네트워크가 따로 필요없고, 가장 빠르며 인증이 불필요하다. <br />
- HTTP : 원격 서버와 통신을 할때 사용한다. 네크워크를 기반으로 API key, OAuth를 지원하는 특징.</p>
<h3>DAta layer</h3>
<hr />
<p><img alt="🎐 Agentic AI - tools" src="./images/img-008.png" /><br />
서로 client, server 측에서 양측에 제공해야하는 것들이 무엇일까?<br />
- server는 tool, resource, prompt(LLM에게 제공할) 을 보내야하고,<br />
- client는 Notification, sampling은 (LLM completeion여부, LLM 자체의 reponse)를 보내주어야 한다.</p>
<p>이러한 data들을 <code>primitive</code>라고 정의하고, 각각 primitivie마다 JSON-RPC 형식을 따른다.</p>
<pre><code class="language-coffeescript">RPC : 다른 컴퓨터에 있는 함수를 마치 내 코드안에 있는 함수처럼 호출하는 방식. 
JSON-RPC : RPC중에서 주고 받는 파일이 json형식 파일.
</code></pre>
<p>그리고 다음 procedure이 이루어진다.</p>
<h3>1. Initialization</h3>
<p>단순하게 서로 정보를 주고 받아서, 통신이 원활한지 확인을 하는 가장 기본적인 과정이다.<br />
<img alt="🎐 Agentic AI - tools" src="./images/img-009.png" /></p>
<h3>2. Tool Discovery (at the MCP-server)</h3>
<p>사실 built in tools와 동일하다. 현재 MCP server가 가지고 있는 tools이 뭐가 있는지 check하는 과정.<br />
<img alt="🎐 Agentic AI - tools" src="./images/img-010.png" /></p>
<h3>3. Tool exectution</h3>
<p>이제 LLM에서 prompt와 available tools를 가지고, 현재 상황에서 어떤 tool을 써야할지를 정했을 것이고, 그거를 바탕으로 실행하는 단계이다.<br />
<img alt="🎐 Agentic AI - tools" src="./images/img-011.png" /></p>
<p>e.g.) Request: 날씨가 어떤지 확인하기 위해 client → server 요청  (JSON-RPC 2.0 형식)</p>
<pre><code class="language-coffeescript">{
  &quot;jsonrpc&quot;: &quot;2.0&quot;,
  &quot;id&quot;: 3,
  &quot;method&quot;: &quot;tools/call&quot;,
  &quot;params&quot;: {
    &quot;name&quot;: &quot;weather_current&quot;,
    &quot;arguments&quot;: {
      &quot;location&quot;: &quot;San Francisco&quot;,
      &quot;units&quot;: &quot;imperial&quot;
    }
  }
}
</code></pre>
<p>Response: 날씨를 MCP-server tool로 확인하고 답변 server → client (JSON-RPC 2.0 형식)</p>
<pre><code class="language-coffeescript">{
  &quot;jsonrpc&quot;: &quot;2.0&quot;,
  &quot;id&quot;: 3,
  &quot;result&quot;: {
    &quot;content&quot;: [
      {
        &quot;type&quot;: &quot;text&quot;,
        &quot;text&quot;: &quot;Current weather in San Francisco: 68°F, partly cloudy with light winds from the west at 8 mph. Humidity: 65%&quot;
      }
    ]
  }
}
</code></pre>
<h3>4. Real - time Updates (Notificiation)</h3>
<p>단순하게 서로 변경사항, (예를들어서 tool이 더 생겼거나, 제거됬다던지, resousrces가 바뀌었다던지) 이런 것들을 서로 주고 받는 단계이다.</p>
<p>여기까지가 MCP tool사용하는 프로세스이고, tools execution에서 생략된 API호출에 대해서 살펴보자.<br />
(가장 중요함)</p>
<h1>[API request]</h1>
<p>마법처럼 오늘 날씨를 MCP server → client로  알려주었지만, 사실 세부적으로는 API호출의 과정이 생략 되었다. </p>
<p><span underline="true"><strong>#API 란 application Programming Intefrace </strong></span><br />
→ 프로그램과 프로그램이 대화하기 위한 공식적인 인터페이스.<br />
<img alt="🎐 Agentic AI - tools" src="./images/img-012.png" /></p>
<p>여기서, 이제 MCP server가 API인증키를 가지고 있고, 아래의 호출을 하게 되면, MCP server가 얻는 답변은 다음과 같다.<br />
<img alt="🎐 Agentic AI - tools" src="./images/img-013.png" /></p>
<p>여기서 호출 방식 (문법은) 각 application API문서에 게시 되어 있고 (아래는 기상청 API)<br />
<img alt="🎐 Agentic AI - tools" src="./images/img-014.png" /></p>
<p>API 문서는 각 Application마다 전부 다양하다.<br />
<img alt="🎐 Agentic AI - tools" src="./images/img-015.png" /></p>
<p><strong>여기서, 중요한 점은 MCP server가 이 API문서를 읽지 않는 다는 것이다.</strong><br />
(마법처럼 MCP server가 이거를 읽고, 어떤 함수로 호출을 하고, 얻는 답변은 무엇인지를 스스로 판단하지 않는다.)</p>
<p>따라서, Application사용을 도구처럼 이용하기 위해서는 우리가 API 문서를 읽고 함수의 형태로 MCP server에 저장해놓아야 API호출을 적절히 하여, 원하는 답을 얻을 수 있다.</p>
<pre><code class="language-shell">def weather_current(location):
    response = requests.get(
        &quot;https://weather.go.kr/api/current&quot;,
        params={&quot;city&quot;: location},
        headers={&quot;Authorization&quot;: &quot;Bearer SECRET&quot;}
    )
    data = response.json()
    return format_to_mcp(data)
</code></pre>
<p>(그렇다면, 우리를 위해서 누군가가 API를 읽고, client ↔ server 통신이 가능한 json-rpc형식으로 변환함수를 만들어 놓았고, 그것들이 여러 github or market에 존재하는 것)<br />
<a href="https://mcpmarket.com/ko">최고의 MCP 서버 찾기 | MCP 마켓</a></p>
<p>최종적으로, weather API ↔ server ↔ client 호출은 다음과 같이 진행된다.<br />
<img alt="🎐 Agentic AI - tools" src="./images/img-016.png" /></p>
<ol>
<li>tool discovery 단계에서 LLM은 현재 상황에서 tool을 선택했고, 어떻게 output해야할지를 인지하고, MCP host에게 전달.</li>
<li>MPC host는 해당 도구가 연결된 MCP client를 pick한다음에, json - rpc 2.0형식에 맞게 정보를 전달한다.</li>
<li>정보를 받은 MCP server는 tool + 전달받은 정보 → API 호출 함수를 command</li>
<li>최종적으로 얻고자하는 정보를 API로부터 받는다. (e.g.) temp : 26</li>
<li>이제 얻은 정보를 다시 MCP client에게 전달.(json rpc 2.0형태로 반환)</li>
</ol>
<h1>Concolusion</h1>
<hr />
<p>이번시간에는 AGenti가 도구를 어떻게 사용하는지를 알아보았고, 기본적으로는 동일한 process로 진행되는 것을 확인하였다.<br />
1. 도구 탐색후 선택<br />
2. 도구 실행<br />
3. 결과 관찰 및 유저 output</p>
<p>그리고 사용할 수 있는 도구는 크게 3가지<br />
1. Built-in client tools<br />
2. Built-in server tools<br />
3. MCP server tools</p>
<p>가 존재하는 것을 확인하였다.</p>
<p>개인적인 생각으로는 핵심은 두가지다. 인간이 만들어 놓은 도구들을 agent가 쓸수 있도록 만든 protocol인 MCP가 계속해서 확장되어 다양한 tool들에 agent가 접근 가능 할 것.<br />
<img alt="🎐 Agentic AI - tools" src="./images/img-017.png" /><br />
(사용가능한 applications)<br />
그리고 이렇게 많은 tool들 중에서 무엇을 어느 타이밍에 쓸지를 agent가 판단을 할 수 는 있지만, tool이 많아 질수록 LLM context window증가로 더 어려워질 수 도 있다. 따라서 이용자가 그것을 대신 잘 판단한다면, 더 productive한 사용을 할 수 있다는 생각이 든다.</p></article>
      <footer class="site-footer">
        <p>&copy; 2026 Sehyeog Kim. Built with gitfolio-inspired theme.</p>
      </footer>
    </main>
  </div>

  <script src="../../../assets/js/main.js"></script>
</body>
</html>