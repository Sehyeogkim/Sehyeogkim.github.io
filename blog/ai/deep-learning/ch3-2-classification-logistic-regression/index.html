<!DOCTYPE html>
<html lang="ko" data-theme="light">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Ch3_2. Classification_Logistic Regression | Sehyeog Kim</title>
  <link rel="stylesheet" href="../../../../assets/css/style.css">
  <script>!function(){var t=localStorage.getItem("theme")||"light";document.documentElement.setAttribute("data-theme",t)}();</script>
</head>
<body>
  <button class="theme-toggle" aria-label="Toggle theme"><svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg><svg class="icon-moon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/></svg></button>

  <header class="mobile-header">
    <span class="site-title">Sehyeog Kim</span>
    <button class="menu-toggle" aria-label="Menu">&#9776;</button>
  </header>
  <div class="sidebar-overlay"></div>

  <div class="site-wrapper">
    <aside class="sidebar">
      <div class="sidebar-bg">
        <img src="../../../../assets/images/bg.jpg" alt="Background" onerror="this.style.display='none'">
      </div>
      <div class="sidebar-profile">
        <img class="profile-photo" src="../../../../assets/images/profile.jpg" alt="Sehyeog Kim"
             onerror="this.style.background='#eaeef2'">
        <h1 class="profile-name">Sehyeog Kim</h1>
        <p class="profile-bio">AI &amp; Computational Engineering<br>Personal Blog</p>
        <div class="profile-links">
          <a href="https://github.com/Sehyeogkim" target="_blank" rel="noopener">
            <svg viewBox="0 0 16 16" width="15" height="15" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg> GitHub
          </a>
        </div>
      </div>
      <nav class="sidebar-nav">
        <a href="/" class="nav-item nav-home">Home</a>
        <span class="nav-group-label">AI</span>
        <a href="/blog/ai/agentic-ai-theory/" class="nav-item">Agentic_AI_Theory<span class="nav-post-count">8</span></a>
        <a href="/blog/ai/deep-learning/" class="nav-item active">Deep-learning<span class="nav-post-count">14</span></a>
        <a href="/blog/ai/machine-learning/" class="nav-item">Machine_Learning<span class="nav-post-count">11</span></a>
        <a href="/blog/ai/sensitivity-analysis/" class="nav-item">Sensitivity_Analysis<span class="nav-post-count">3</span></a>
        <span class="nav-group-label">AI_Application</span>
        <a href="/blog/ai_application/claude/" class="nav-item">Claude<span class="nav-post-count">2</span></a>
        <span class="nav-group-label">BioMechanics</span>
        <a href="/blog/biomechanics/blood-flow-and-metabolism/" class="nav-item">Blood-Flow-and-Metabolism<span class="nav-post-count">12</span></a>
        <a href="/blog/biomechanics/cardiovascular-diseases/" class="nav-item">CardioVascular_Diseases<span class="nav-post-count">8</span></a>
        <span class="nav-group-label">Mechanical_Engineering</span>
        <a href="/blog/mechanical-engineering/computational-linear-algebra/" class="nav-item">Computational-Linear-Algebra<span class="nav-post-count">15</span></a>
        <a href="/blog/mechanical-engineering/computational-fluid-dynamics/" class="nav-item">Computational_Fluid_Dynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/continuum-mechanics/" class="nav-item">Continuum-Mechanics<span class="nav-post-count">9</span></a>
        <a href="/blog/mechanical-engineering/engineering-mathematics/" class="nav-item">Engineering_Mathematics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/finite-element-method/" class="nav-item">Finite-Element-Method<span class="nav-post-count">1</span></a>
        <a href="/blog/mechanical-engineering/fluid-mechanics/" class="nav-item">Fluid_Mechanics<span class="nav-post-count">18</span></a>
        <a href="/blog/mechanical-engineering/gas-dynamics/" class="nav-item">Gas_Dynamics<span class="nav-post-count">24</span></a>
        <a href="/blog/mechanical-engineering/heat-transfer/" class="nav-item">Heat-transfer<span class="nav-post-count">8</span></a>
        <a href="/blog/mechanical-engineering/solid-mechanics/" class="nav-item">Solid_Mechanics<span class="nav-post-count">25</span></a>
        <a href="/blog/mechanical-engineering/thermodynamics/" class="nav-item">Thermodynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/viscous-flow/" class="nav-item">Viscous_Flow<span class="nav-post-count">28</span></a>
      </nav>
    </aside>

    <main class="main-content">
      <div class="breadcrumb"><a href="/">Home</a><span class="sep">/</span><a href="/blog/ai/">AI</a><span class="sep">/</span><a href="/blog/ai/deep-learning/">Deep-learning</a><span class="sep">/</span><span>Ch3_2. Classification_Logistic Regression</span></div>
<a href="/blog/ai/deep-learning/" class="back-link">&larr; Back to Deep-learning</a>
<div class="page-header"><h1>Ch3_2. Classification_Logistic Regression</h1></div>
<div class="post-meta"><span class="meta-item"><span class="meta-label">Date:</span> 2024-09-25</span><span class="meta-item"><span class="meta-label">Category:</span> Deep-learning</span><span class="meta-item"><span class="meta-label">Source:</span> <a href="https://jeffdissel.tistory.com/98" target="_blank" rel="noopener">link</a></span></div>
<article class="post-content"><p>지난 포스터에서는,<br />
class가 다른 점들을 분류하는<br />
구분선을 어떻게 정의하는지<br />
에 대해서 알아보았다.<br />
그렇다면, 이런 질문이 들 수 있다.<br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-001.png" /><br />
위 두 직선 모두, 서로 다른 클라쓰의 두점을<br />
구분하였다고 가정하자.<br />
그랬을때, 두 구분선중에서<br />
무엇이 더 잘 구분한 구분선인가??<br />
바로, 점들과 구분선 사이의 거리의 합이 최소일때, 즉<br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-002.png" /><br />
산술기하평균에서 배웠듯이,<br />
거리의 곱들이 최소인 순간이다.<br />
거리의 표현이<br />
g(x) / ||w||<br />
라는 것은 지난시간 증명 완료 하였고,<br />
결국, w,x의 내적과 비례하다는 것을 도출 할 수 있다.<br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-003.png" /><br />
이후, 거리의 범위가 너무 넓기 때문에<br />
강제로, 0과 1사이의 범위로 축소해준다.<br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-004.png" /><br />
범위가 무한인 h를 0-1사이의 범위로<br />
스케일 다운 시켜주는 함수를<br />
logistic function<br />
이라고 부르고 다양한 종류가 존재한다.<br />
그 중에서, 대표적인 함수는 sigmoid function<br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-005.png" /><br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-006.png" /><br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-005.png" /><br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-006.png" /><br />
sigmoid function graph<br />
그렇다면, 왜 0-1사이로 바꾸었는가?/<br />
바로 확률의 관점으로 계산 할 수 있기 때문이다!.<br />
도출 값이 1일 확률, 과 0 일 확률 두가지를<br />
다음과 같이 시그모이드 함수로 나타낼 수 있다.<br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-007.png" /><br />
다시, logistic function hw(x) 형태로 나타내고,<br />
그중에서 우리는 시그모이드 함수를 사용할 것이다.<br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-008.png" /><br />
위의 식을 합쳐서 표현해보면.<br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-009.png" /><br />
위 확률의 의미를 정확히 이해하고 넘어가자.<br />
데이터상 x = 0 y = 1이라고 하자.<br />
그렇다면, 지금 현재 w는<br />
P(y=1 | x;w) = hw(x) 를 증가 시켜야 한다.<br />
(y=1일 확률)<br />
만약에, x=0, y=0 인 경우는<br />
현재 w는<br />
1-hw(x) 를 증가시켜야 한다.<br />
(y=1일 확률을 낮춰야함)<br />
따라서, 결론적으로<br />
P(y | x;w)가 의미하는 것은, w(변수)가 올게 판단하는 정도를<br />
나타낸다.<br />
자 이제 w 기준으로, 각각 모든 데이터의 확률을 곱한 것이 바로.<br />
L(w): Likelihodd function 이고<br />
이는, 지금 w 기준으로,<br />
모든 데이터들에 대하여 올바르게 판단한 정도를 나타낸다.<br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-010.png" /><br />
따라서, L(w) 를 최대화 시키는 w를 찾아야 한다.<br />
지수형태이므로, log를 씌우면 더 간단하게 다음과같이 나타낼 수 있고,<br />
log likelihood function<br />
이라고 부른다.<br />
<img alt="Ch3_2. Classification_Logistic Regression" src="./images/img-011.png" /><br />
즉, l(w) 를 최대로 하는<br />
-l(w)를 최소로하는<br />
optimization 문제라는 것이다.<br />
따라서, deep learning이 최적화 라는 것.</p></article>
      <footer class="site-footer">
        <p>&copy; 2026 Sehyeog Kim</p>
      </footer>
    </main>
  </div>
  <script src="../../../../assets/js/main.js"></script>
</body>
</html>