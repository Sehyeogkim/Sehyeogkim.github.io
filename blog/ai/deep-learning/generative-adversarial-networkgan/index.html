<!DOCTYPE html>
<html lang="ko" data-theme="light">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Generative Adversarial Network(GAN) | Sehyeog Kim</title>
  <link rel="stylesheet" href="../../../../assets/css/style.css">
  <script>!function(){var t=localStorage.getItem("theme")||"light";document.documentElement.setAttribute("data-theme",t)}();</script>
</head>
<body>
  <button class="theme-toggle" aria-label="Toggle theme"><svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg><svg class="icon-moon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/></svg></button>

  <header class="mobile-header">
    <span class="site-title">Sehyeog Kim</span>
    <button class="menu-toggle" aria-label="Menu">&#9776;</button>
  </header>
  <div class="sidebar-overlay"></div>

  <div class="site-wrapper">
    <aside class="sidebar">
      <div class="sidebar-bg">
        <img src="../../../../assets/images/bg.jpg" alt="Background" onerror="this.style.display='none'">
      </div>
      <div class="sidebar-profile">
        <img class="profile-photo" src="../../../../assets/images/profile.jpg" alt="Sehyeog Kim"
             onerror="this.style.background='#eaeef2'">
        <h1 class="profile-name">Sehyeog Kim</h1>
        <p class="profile-bio">AI &amp; Computational Engineering<br>Personal Blog</p>
        <div class="profile-links">
          <a href="https://github.com/Sehyeogkim" target="_blank" rel="noopener">
            <svg viewBox="0 0 16 16" width="15" height="15" fill="currentColor"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg> GitHub
          </a>
        </div>
      </div>
      <nav class="sidebar-nav">
        <a href="/" class="nav-item nav-home">Home</a>
        <span class="nav-group-label">AI</span>
        <a href="/blog/ai/agentic-ai-theory/" class="nav-item">Agentic_AI_Theory<span class="nav-post-count">8</span></a>
        <a href="/blog/ai/deep-learning/" class="nav-item active">Deep-learning<span class="nav-post-count">14</span></a>
        <a href="/blog/ai/machine-learning/" class="nav-item">Machine_Learning<span class="nav-post-count">11</span></a>
        <a href="/blog/ai/sensitivity-analysis/" class="nav-item">Sensitivity_Analysis<span class="nav-post-count">3</span></a>
        <span class="nav-group-label">BioMechanics</span>
        <a href="/blog/biomechanics/blood-flow-and-metabolism/" class="nav-item">Blood-Flow-and-Metabolism<span class="nav-post-count">12</span></a>
        <a href="/blog/biomechanics/cardiovascular-diseases/" class="nav-item">CardioVascular_Diseases<span class="nav-post-count">8</span></a>
        <span class="nav-group-label">Mechanical_Engineering</span>
        <a href="/blog/mechanical-engineering/computational-linear-algebra/" class="nav-item">Computational-Linear-Algebra<span class="nav-post-count">15</span></a>
        <a href="/blog/mechanical-engineering/computational-fluid-dynamics/" class="nav-item">Computational_Fluid_Dynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/continuum-mechanics/" class="nav-item">Continuum-Mechanics<span class="nav-post-count">9</span></a>
        <a href="/blog/mechanical-engineering/engineering-mathematics/" class="nav-item">Engineering_Mathematics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/finite-element-method/" class="nav-item">Finite-Element-Method<span class="nav-post-count">1</span></a>
        <a href="/blog/mechanical-engineering/fluid-mechanics/" class="nav-item">Fluid_Mechanics<span class="nav-post-count">18</span></a>
        <a href="/blog/mechanical-engineering/gas-dynamics/" class="nav-item">Gas_Dynamics<span class="nav-post-count">24</span></a>
        <a href="/blog/mechanical-engineering/heat-transfer/" class="nav-item">Heat-transfer<span class="nav-post-count">8</span></a>
        <a href="/blog/mechanical-engineering/solid-mechanics/" class="nav-item">Solid_Mechanics<span class="nav-post-count">25</span></a>
        <a href="/blog/mechanical-engineering/thermodynamics/" class="nav-item">Thermodynamics<span class="nav-post-count">14</span></a>
        <a href="/blog/mechanical-engineering/viscous-flow/" class="nav-item">Viscous_Flow<span class="nav-post-count">28</span></a>
      </nav>
    </aside>

    <main class="main-content">
      <div class="breadcrumb"><a href="/">Home</a><span class="sep">/</span><a href="/blog/ai/">AI</a><span class="sep">/</span><a href="/blog/ai/deep-learning/">Deep-learning</a><span class="sep">/</span><span>Generative Adversarial Network(GAN)</span></div>
<a href="/blog/ai/deep-learning/" class="back-link">&larr; Back to Deep-learning</a>
<div class="page-header"><h1>Generative Adversarial Network(GAN)</h1></div>
<div class="post-meta"><span class="meta-item"><span class="meta-label">Date:</span> 2024-12-11</span><span class="meta-item"><span class="meta-label">Category:</span> Deep-learning</span><span class="meta-item"><span class="meta-label">Source:</span> <a href="https://jeffdissel.tistory.com/141" target="_blank" rel="noopener">link</a></span></div>
<article class="post-content"><p>지금까지 우리는<br />
Supervised Learning에 대해서<br />
알아보았다.<br />
즉, 어떠한 데이터를 우리가 정답이랑 같이<br />
model에 줌으로써,<br />
모델을 이 새로운 데이터를 만났을 때,<br />
학습을 바탕으로 판단하도록<br />
학습시키는 방식이다.<br />
그러면, 사용자가 데이터를 주지 않아도,<br />
모델을 학습시킬수는 없을까?<br />
사용자가 데이터가 부족하거나 없을 수 있으니까.<br />
이를 달성한 모델이 바로,<br />
Generative model<br />
이다.<br />
아래 사진을 보면,<br />
generator - generative model<br />
은<br />
random noise(저차원정보)<br />
를 활용하여,<br />
사진을 하나 만들어 낸다.<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-001.png" /><br />
중요한것은 random . 한 noise라는 것이다.<br />
따라서, 사용자가 임의로 집어 넣은 input(supervised learning)과는<br />
다른 unsupervised Learning이라는 것.<br />
예시를 통해서 정확히 다시 이해해 보자.<br />
input distibution - normal distribution으로<br />
고정된 모양과 값을 가진 정규분포 확률함수라고 하자.<br />
그랬을때, 중간 과정의 함수에 따라서,<br />
output 이 다르게 나올 것이다.<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-002.png" /><br />
따라서, random noise - input과는<br />
상관없이<br />
generator model(중간 변환박스)<br />
에 따라서<br />
output을 결정할 수 있다는 것이다.<br />
즉, 원하는 output을 얻기위해,<br />
정규분포의 input은 fix<br />
중간 박스<br />
generator model을 학습한다.<br />
그렇다면,<br />
정확히 어떻게 가운데 mapping상자를 훈련시켜야<br />
random noise로 부터, 원하는 output을 얻을 . 수 있을까?<br />
simple 하게<br />
true data 와 generator가 만든<br />
데이터 2개를 비교하면 된다.<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-003.png" /><br />
하지만 여기서 문제가 발생한다.<br />
지금 우리가 보고 있는 output은 image 2D이지만,<br />
굉장히 차수가<br />
높은 고차원 공간<br />
이라면,<br />
generated data,<br />
true data두개를 비교하기란 쉽지 않다.<br />
이 문제를 해결하기 위해.<br />
generator가 만든 output과<br />
true output을 비교해주는<br />
'discriminator'<br />
이라는 모델을 따로 설정한다.<br />
Discriminator는,<br />
Generator가 만든 가짜 사진<br />
+ 사용자가 준 진짜 사진<br />
을 보고,<br />
진짜와 가짜를 구분하는 역할을 한다.<br />
이게 바로,<br />
Generative Adversial Networks(GAN)<br />
의 핵심이다.<br />
다시말해,<br />
Generator는 진짜 같은 가짜사진을 만드는 것이 목적이고<br />
(faker)<br />
Discriminator는 Generator가 만든 사진과 진짜 사진을 보고,<br />
뭐가 진짜고 가짜인지를 제대로 구분하는 것이 목적이다.<br />
(!!!!discriminator도 훈련으로 학습되는 모델임)<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-004.png" /><br />
GAN model structure<br />
이제,<br />
학습과정에서 loss함수를 주목해보자.<br />
discriminator 도 결국 train되는 모델이므로,<br />
진짜를 진짜라고, 가짜를 가짜라고 할 경우<br />
loss 값이 줄어들도록 설계한다.<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-005.png" /><br />
Generator loss같은 경우,<br />
자기가 만든 사진이 최종 output에서 real이라고 나올 경우<br />
, loss값이 줄어들도록 설계한다.<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-006.png" /><br />
(Combined = genreator, discriminator 합친 전체 모델<br />
- 앞의 생략한 tensorflow code에서 정의하였습니다.)</p>
<hr />
<p>위의 구조는 Autoencoder처럼 ANN의 구조로 이루어져 있지만,<br />
CAE처럼 CNN구조로 만든 GAN도 존재한다.<br />
(자세한 내용은 생략)<br />
Deep-Convolutional GAN<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-007.png" /></p>
<hr />
<p>Conditional GAN<br />
basic GAN은 오직 latent space로부터,<br />
output을 만들어 낸다.<br />
이는 2가지 문제점이 존재한다.<br />
1. latent space만 보고 어떤 결과가 나올지 알 수 없다.<br />
(latent space - random 하므로)<br />
2. 모든 클래스의 데이터가 균등하게 생성되지 않고, 다양성이 떨어진다<br />
(latent space 차원의 한계)<br />
따라서 이를  해결하는 방식이 바로,<br />
latent space<br />
+ label 정보<br />
를<br />
더하여, 이미지를 생성하도록 설계한<br />
Conditional GAN<br />
이다.<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-008.png" /><br />
Conditionial GAN</p>
<hr />
<p>Adversarial AutoEncoder<br />
GAN의 discriminator를 다른 model에도<br />
적용시킬 수 있다!!!<br />
(이전에 배운)<br />
autoeocnder의 구조는 다음과 같다.<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-009.png" /><br />
여기서 discriminator를 왜 추가해주나??<br />
바로 latent space를<br />
정규분포 space로 강제로 변환<br />
시켜주기 위해서 이다.<br />
이렇게 밑에서 discriminator를 통해<br />
z가 정규분포를 따르도록 강제해준다.<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-010.png" /><br />
그럼 z가 왜 도대체 정규분포를 따라야 좋은건가???<br />
우리가 오토 인코더에서 할 수 있는 작업 중 하나인,<br />
latent space -&gt; 사진<br />
을 디코더에서 한다고 가정하자.<br />
(이를 우리는 mapping<br />
작업이라고<br />
부른다)<br />
이때, 정규분포를 따르게 되면, 우리가 latent spac를<br />
용이하게 변화시키면서 output의 변화를 관찰할 수 있다.<br />
다시말해, latent space 조작이 훨씬 더 쉽다는 말이다.<br />
(우리는 walking on the latent space<br />
즉 latent space에서의 변환이 실제 사진을<br />
만드는데 어떤 영향을 주는지를 알고 싶어한다)</p>
<hr />
<p>Cycle GAN<br />
이번에는 paired image set을 제작하기 위한,<br />
(목적: unpair image -&gt; generate a pair image)<br />
cycle gan에 대해서 알아 보자.<br />
ex)<br />
우리의 목적: Horse 사진을 가지고, zebra사진을 만드는 모델 계발.<br />
<img alt="Generative Adversarial Network(GAN)" src="./images/img-011.png" /><br />
위 구조를 보면, Cycle Gan은<br />
general GAN과 2가지 빼고 동일하다.<br />
1. input - latentspace가 아니라 진짜 사진이라는 점<br />
2.생성된 zebra사진을<br />
다시 symmetric한 generator를 통과하여 말사진으로 바꾸는점.<br />
Gxy 는 생성한 얼룩말 사진이 discriminator가 real로 판단하도록 학습하고,<br />
Discriminaotr는 real 과 fake를 구분하도록 학습한다.<br />
뿐만아니라, Generator는 얼룩말을 다시 Generator 역함수를 지났을때,<br />
원래 . 말사진이 나오도록 학습한다.<br />
따라서, 마지막 부분에 cycle-consistency loss가 기존 gan과 별개로 추가된다.</p></article>
      <footer class="site-footer">
        <p>&copy; 2026 Sehyeog Kim</p>
      </footer>
    </main>
  </div>
  <script src="../../../../assets/js/main.js"></script>
</body>
</html>